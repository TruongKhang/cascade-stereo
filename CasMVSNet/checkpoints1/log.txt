current time 20200806_131214
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
Epoch 0/16, Iter 0/6761, lr 0.000335, train loss = 275.755, depth loss = 78.748, time = 19.534
Epoch 0/16, Iter 50/6761, lr 0.000401, train loss = 175.545, depth loss = 49.363, time = 3.484
Epoch 0/16, Iter 100/6761, lr 0.000468, train loss = 145.821, depth loss = 40.772, time = 3.906
Epoch 0/16, Iter 150/6761, lr 0.000535, train loss = 189.146, depth loss = 53.110, time = 3.558
Epoch 0/16, Iter 200/6761, lr 0.000601, train loss = 284.946, depth loss = 81.159, time = 3.843
Epoch 0/16, Iter 250/6761, lr 0.000668, train loss = 204.597, depth loss = 57.955, time = 3.951
Epoch 0/16, Iter 300/6761, lr 0.000735, train loss = 184.551, depth loss = 52.415, time = 3.582
Epoch 0/16, Iter 350/6761, lr 0.000801, train loss = 103.318, depth loss = 28.939, time = 3.741
Epoch 0/16, Iter 400/6761, lr 0.000868, train loss = 169.210, depth loss = 47.962, time = 3.450
Epoch 0/16, Iter 450/6761, lr 0.000935, train loss = 100.469, depth loss = 28.341, time = 4.082
Epoch 0/16, Iter 500/6761, lr 0.001000, train loss = 51.426, depth loss = 14.234, time = 3.352
Epoch 0/16, Iter 550/6761, lr 0.001000, train loss = 53.437, depth loss = 14.676, time = 3.351
Epoch 0/16, Iter 600/6761, lr 0.001000, train loss = 79.993, depth loss = 22.414, time = 3.566
Epoch 0/16, Iter 650/6761, lr 0.001000, train loss = 88.415, depth loss = 24.846, time = 3.418
Epoch 0/16, Iter 700/6761, lr 0.001000, train loss = 65.981, depth loss = 18.444, time = 3.394
Epoch 0/16, Iter 750/6761, lr 0.001000, train loss = 83.256, depth loss = 23.288, time = 3.638
Epoch 0/16, Iter 800/6761, lr 0.001000, train loss = 31.141, depth loss = 8.406, time = 3.584
Epoch 0/16, Iter 850/6761, lr 0.001000, train loss = 107.965, depth loss = 30.767, time = 3.764
Epoch 0/16, Iter 900/6761, lr 0.001000, train loss = 187.633, depth loss = 53.012, time = 3.560
Epoch 0/16, Iter 950/6761, lr 0.001000, train loss = 89.435, depth loss = 25.136, time = 3.906
Epoch 0/16, Iter 1000/6761, lr 0.001000, train loss = 128.150, depth loss = 35.771, time = 3.396
Epoch 0/16, Iter 1050/6761, lr 0.001000, train loss = 60.894, depth loss = 17.258, time = 3.493
Epoch 0/16, Iter 1100/6761, lr 0.001000, train loss = 28.699, depth loss = 7.885, time = 3.833
Epoch 0/16, Iter 1150/6761, lr 0.001000, train loss = 72.901, depth loss = 20.132, time = 3.921
Epoch 0/16, Iter 1200/6761, lr 0.001000, train loss = 32.395, depth loss = 8.983, time = 4.481
Epoch 0/16, Iter 1250/6761, lr 0.001000, train loss = 70.283, depth loss = 19.906, time = 3.624
Epoch 0/16, Iter 1300/6761, lr 0.001000, train loss = 23.808, depth loss = 6.538, time = 3.791
current time 20200806_142442
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
Epoch 0/16, Iter 0/6761, lr 0.000335, train loss = 276.953, depth loss = 79.101, time = 19.736
Epoch 0/16, Iter 50/6761, lr 0.000401, train loss = 218.496, depth loss = 62.387, time = 3.442
Epoch 0/16, Iter 100/6761, lr 0.000468, train loss = 264.916, depth loss = 75.607, time = 3.602
Epoch 0/16, Iter 150/6761, lr 0.000535, train loss = 273.969, depth loss = 78.226, time = 3.597
Epoch 0/16, Iter 200/6761, lr 0.000601, train loss = 377.151, depth loss = 107.698, time = 3.273
Epoch 0/16, Iter 250/6761, lr 0.000668, train loss = 357.924, depth loss = 102.182, time = 3.479
Epoch 0/16, Iter 300/6761, lr 0.000735, train loss = 340.439, depth loss = 97.183, time = 3.688
Epoch 0/16, Iter 350/6761, lr 0.000801, train loss = 234.306, depth loss = 66.852, time = 3.578
Epoch 0/16, Iter 400/6761, lr 0.000868, train loss = 326.215, depth loss = 93.076, time = 3.382
Epoch 0/16, Iter 450/6761, lr 0.000935, train loss = 344.898, depth loss = 98.410, time = 3.555
Epoch 0/16, Iter 500/6761, lr 0.001000, train loss = 270.413, depth loss = 77.111, time = 3.670
Epoch 0/16, Iter 550/6761, lr 0.001000, train loss = 364.487, depth loss = 104.049, time = 3.341
Epoch 0/16, Iter 600/6761, lr 0.001000, train loss = 326.480, depth loss = 93.173, time = 3.438
Epoch 0/16, Iter 650/6761, lr 0.001000, train loss = 260.635, depth loss = 74.375, time = 3.389
current time 20200806_145932
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
current time 20200806_150039
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
Epoch 0/16, Iter 0/6761, lr 0.000335, train loss = 410.239, depth loss = 117.147, time = 19.494
Epoch 0/16, Iter 50/6761, lr 0.000401, train loss = 222.913, depth loss = 63.162, time = 3.329
Epoch 0/16, Iter 100/6761, lr 0.000468, train loss = 228.290, depth loss = 65.154, time = 3.685
Epoch 0/16, Iter 150/6761, lr 0.000535, train loss = 260.278, depth loss = 74.218, time = 3.598
Epoch 0/16, Iter 200/6761, lr 0.000601, train loss = 307.883, depth loss = 87.965, time = 3.704
Epoch 0/16, Iter 250/6761, lr 0.000668, train loss = 349.264, depth loss = 99.175, time = 3.415
Epoch 0/16, Iter 300/6761, lr 0.000735, train loss = 241.950, depth loss = 68.455, time = 3.558
Epoch 0/16, Iter 350/6761, lr 0.000801, train loss = 293.162, depth loss = 83.264, time = 3.312
Epoch 0/16, Iter 400/6761, lr 0.000868, train loss = 226.217, depth loss = 64.174, time = 3.377
Epoch 0/16, Iter 450/6761, lr 0.000935, train loss = 281.311, depth loss = 79.813, time = 3.537
Epoch 0/16, Iter 500/6761, lr 0.001000, train loss = 266.798, depth loss = 75.949, time = 3.388
Epoch 0/16, Iter 550/6761, lr 0.001000, train loss = 351.641, depth loss = 99.785, time = 3.445
current time 20200806_152926
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
Epoch 0/16, Iter 0/6761, lr 0.000335, train loss = 396.558, depth loss = 113.340, time = 19.499
Epoch 0/16, Iter 50/6761, lr 0.000401, train loss = 154.897, depth loss = 43.169, time = 3.353
Epoch 0/16, Iter 100/6761, lr 0.000468, train loss = 162.450, depth loss = 45.563, time = 3.565
Epoch 0/16, Iter 150/6761, lr 0.000535, train loss = 241.929, depth loss = 69.093, time = 3.655
Epoch 0/16, Iter 200/6761, lr 0.000601, train loss = 183.299, depth loss = 52.748, time = 3.844
Epoch 0/16, Iter 250/6761, lr 0.000668, train loss = 155.852, depth loss = 44.024, time = 3.421
current time 20200806_154346
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
Epoch 0/16, Iter 0/6761, lr 0.000335, train loss = 410.239, depth loss = 117.147, time = 19.608
Epoch 0/16, Iter 50/6761, lr 0.000401, train loss = 222.628, depth loss = 63.088, time = 3.575
Epoch 0/16, Iter 100/6761, lr 0.000468, train loss = 229.247, depth loss = 65.428, time = 3.587
Epoch 0/16, Iter 150/6761, lr 0.000535, train loss = 261.316, depth loss = 74.577, time = 3.991
Epoch 0/16, Iter 200/6761, lr 0.000601, train loss = 308.489, depth loss = 87.818, time = 4.055
Epoch 0/16, Iter 250/6761, lr 0.000668, train loss = 351.362, depth loss = 99.802, time = 3.604
Epoch 0/16, Iter 300/6761, lr 0.000735, train loss = 238.851, depth loss = 67.432, time = 3.604
Epoch 0/16, Iter 350/6761, lr 0.000801, train loss = 291.924, depth loss = 82.929, time = 3.537
Epoch 0/16, Iter 400/6761, lr 0.000868, train loss = 217.382, depth loss = 61.464, time = 3.358
Epoch 0/16, Iter 450/6761, lr 0.000935, train loss = 275.473, depth loss = 77.951, time = 3.549
current time 20200806_161022
creating new summary file
argv: ['--local_rank=0', '--logdir', 'checkpoints', '--dataset=dtu_yao', '--batch_size=4', '--trainpath=/dev/dtu_dataset/train/', '--trainlist', 'lists/dtu/train.txt', '--testlist', 'lists/dtu/val.txt', '--numdepth=192']
################################  args  ################################
mode      	train                         	<class 'str'>       
model     	mvsnet                        	<class 'str'>       
device    	cuda                          	<class 'str'>       
dataset   	dtu_yao                       	<class 'str'>       
trainpath 	/dev/dtu_dataset/train/       	<class 'str'>       
testpath  	/dev/dtu_dataset/train/       	<class 'str'>       
trainlist 	lists/dtu/train.txt           	<class 'str'>       
testlist  	lists/dtu/val.txt             	<class 'str'>       
epochs    	16                            	<class 'int'>       
lr        	0.001                         	<class 'float'>     
lrepochs  	10,12,14:2                    	<class 'str'>       
wd        	0.0                           	<class 'float'>     
batch_size	4                             	<class 'int'>       
numdepth  	192                           	<class 'int'>       
interval_scale	1.06                          	<class 'float'>     
loadckpt  	None                          	<class 'NoneType'>  
logdir    	checkpoints                   	<class 'str'>       
resume    	False                         	<class 'bool'>      
summary_freq	50                            	<class 'int'>       
save_freq 	1                             	<class 'int'>       
eval_freq 	1                             	<class 'int'>       
seed      	1                             	<class 'int'>       
pin_m     	False                         	<class 'bool'>      
local_rank	0                             	<class 'int'>       
share_cr  	False                         	<class 'bool'>      
ndepths   	48,32,8                       	<class 'str'>       
depth_inter_r	4,2,1                         	<class 'str'>       
dlossw    	0.5,1.0,2.0                   	<class 'str'>       
cr_base_chs	8,8,8                         	<class 'str'>       
grad_method	detach                        	<class 'str'>       
using_apex	False                         	<class 'bool'>      
sync_bn   	False                         	<class 'bool'>      
opt_level 	O0                            	<class 'str'>       
keep_batchnorm_fp32	None                          	<class 'NoneType'>  
loss_scale	None                          	<class 'NoneType'>  
########################################################################
**********netphs:[48, 32, 8], depth_intervals_ratio:[4.0, 2.0, 1.0],  grad:detach, chs:[8, 8, 8]************
*************feature extraction arch mode:fpn****************
start at epoch 0
Number of model parameters: 934304
Let's use 1 GPUs!
mvsdataset kwargs {'shuffle': True, 'seq_size': 49, 'batch_size': 4}
dataset train metas: 27097
mvsdataset kwargs {'shuffle': False, 'seq_size': 49, 'batch_size': 1}
dataset val metas: 6174
Epoch 0:
Epoch 0/16, Iter 0/6761, lr 0.000335, train loss = 396.558, depth loss = 113.340, time = 19.545
Epoch 0/16, Iter 50/6761, lr 0.000401, train loss = 143.710, depth loss = 40.425, time = 3.529
Epoch 0/16, Iter 100/6761, lr 0.000468, train loss = 165.240, depth loss = 46.276, time = 3.522
Epoch 0/16, Iter 150/6761, lr 0.000535, train loss = 214.882, depth loss = 60.915, time = 4.136
Epoch 0/16, Iter 200/6761, lr 0.000601, train loss = 190.989, depth loss = 53.831, time = 3.488
Epoch 0/16, Iter 250/6761, lr 0.000668, train loss = 155.750, depth loss = 44.800, time = 3.656
Epoch 0/16, Iter 300/6761, lr 0.000735, train loss = 122.110, depth loss = 34.823, time = 3.572
Epoch 0/16, Iter 350/6761, lr 0.000801, train loss = 57.476, depth loss = 16.258, time = 3.491
Epoch 0/16, Iter 400/6761, lr 0.000868, train loss = 50.816, depth loss = 14.519, time = 3.606
Epoch 0/16, Iter 450/6761, lr 0.000935, train loss = 34.848, depth loss = 9.678, time = 3.468
Epoch 0/16, Iter 500/6761, lr 0.001000, train loss = 104.525, depth loss = 29.556, time = 3.612
Epoch 0/16, Iter 550/6761, lr 0.001000, train loss = 103.661, depth loss = 29.455, time = 4.028
Epoch 0/16, Iter 600/6761, lr 0.001000, train loss = 46.826, depth loss = 13.070, time = 3.731
Epoch 0/16, Iter 650/6761, lr 0.001000, train loss = 84.855, depth loss = 23.816, time = 3.434
Epoch 0/16, Iter 700/6761, lr 0.001000, train loss = 77.054, depth loss = 21.909, time = 3.637
Epoch 0/16, Iter 750/6761, lr 0.001000, train loss = 85.630, depth loss = 24.098, time = 3.482
Epoch 0/16, Iter 800/6761, lr 0.001000, train loss = 90.145, depth loss = 25.434, time = 3.300
Epoch 0/16, Iter 850/6761, lr 0.001000, train loss = 88.428, depth loss = 24.969, time = 3.374
Epoch 0/16, Iter 900/6761, lr 0.001000, train loss = 120.066, depth loss = 33.974, time = 3.751
Epoch 0/16, Iter 950/6761, lr 0.001000, train loss = 137.704, depth loss = 39.139, time = 4.145
Epoch 0/16, Iter 1000/6761, lr 0.001000, train loss = 60.877, depth loss = 17.062, time = 3.438
Epoch 0/16, Iter 1050/6761, lr 0.001000, train loss = 27.161, depth loss = 7.474, time = 3.595
Epoch 0/16, Iter 1100/6761, lr 0.001000, train loss = 42.037, depth loss = 11.757, time = 3.618
Epoch 0/16, Iter 1150/6761, lr 0.001000, train loss = 33.765, depth loss = 9.390, time = 3.635
Epoch 0/16, Iter 1200/6761, lr 0.001000, train loss = 35.100, depth loss = 9.864, time = 4.196
Epoch 0/16, Iter 1250/6761, lr 0.001000, train loss = 15.061, depth loss = 4.092, time = 3.724
Epoch 0/16, Iter 1300/6761, lr 0.001000, train loss = 27.767, depth loss = 7.935, time = 3.358
Epoch 0/16, Iter 1350/6761, lr 0.001000, train loss = 27.084, depth loss = 7.508, time = 3.664
Epoch 0/16, Iter 1400/6761, lr 0.001000, train loss = 63.305, depth loss = 18.097, time = 3.724
Epoch 0/16, Iter 1450/6761, lr 0.001000, train loss = 37.960, depth loss = 10.404, time = 3.602
Epoch 0/16, Iter 1500/6761, lr 0.001000, train loss = 6.849, depth loss = 1.720, time = 3.532
Epoch 0/16, Iter 1550/6761, lr 0.001000, train loss = 8.105, depth loss = 2.131, time = 3.441
Epoch 0/16, Iter 1600/6761, lr 0.001000, train loss = 26.001, depth loss = 7.150, time = 3.486
Epoch 0/16, Iter 1650/6761, lr 0.001000, train loss = 8.535, depth loss = 2.290, time = 3.417
Epoch 0/16, Iter 1700/6761, lr 0.001000, train loss = 21.241, depth loss = 5.744, time = 3.486
Epoch 0/16, Iter 1750/6761, lr 0.001000, train loss = 36.836, depth loss = 9.777, time = 3.268
Epoch 0/16, Iter 1800/6761, lr 0.001000, train loss = 68.626, depth loss = 18.833, time = 3.867
Epoch 0/16, Iter 1850/6761, lr 0.001000, train loss = 61.355, depth loss = 16.787, time = 3.467
Epoch 0/16, Iter 1900/6761, lr 0.001000, train loss = 72.255, depth loss = 20.385, time = 3.796
Epoch 0/16, Iter 1950/6761, lr 0.001000, train loss = 29.393, depth loss = 7.872, time = 3.550
Epoch 0/16, Iter 2000/6761, lr 0.001000, train loss = 39.926, depth loss = 11.062, time = 3.318
Epoch 0/16, Iter 2050/6761, lr 0.001000, train loss = 16.455, depth loss = 4.418, time = 3.841
Epoch 0/16, Iter 2100/6761, lr 0.001000, train loss = 33.427, depth loss = 9.143, time = 3.747
Epoch 0/16, Iter 2150/6761, lr 0.001000, train loss = 13.074, depth loss = 3.514, time = 3.613
Epoch 0/16, Iter 2200/6761, lr 0.001000, train loss = 38.526, depth loss = 10.820, time = 4.479
Epoch 0/16, Iter 2250/6761, lr 0.001000, train loss = 27.679, depth loss = 7.680, time = 4.383
Epoch 0/16, Iter 2300/6761, lr 0.001000, train loss = 12.407, depth loss = 3.284, time = 3.498
Epoch 0/16, Iter 2350/6761, lr 0.001000, train loss = 27.581, depth loss = 7.682, time = 3.896
Epoch 0/16, Iter 2400/6761, lr 0.001000, train loss = 58.624, depth loss = 16.605, time = 3.317
Epoch 0/16, Iter 2450/6761, lr 0.001000, train loss = 66.183, depth loss = 18.905, time = 3.734
Epoch 0/16, Iter 2500/6761, lr 0.001000, train loss = 19.249, depth loss = 5.332, time = 3.220
Epoch 0/16, Iter 2550/6761, lr 0.001000, train loss = 59.840, depth loss = 16.933, time = 3.411
Epoch 0/16, Iter 2600/6761, lr 0.001000, train loss = 57.580, depth loss = 16.166, time = 3.928
Epoch 0/16, Iter 2650/6761, lr 0.001000, train loss = 77.397, depth loss = 21.841, time = 3.469
Epoch 0/16, Iter 2700/6761, lr 0.001000, train loss = 54.220, depth loss = 15.302, time = 3.450
Epoch 0/16, Iter 2750/6761, lr 0.001000, train loss = 29.937, depth loss = 8.279, time = 3.513
Epoch 0/16, Iter 2800/6761, lr 0.001000, train loss = 59.946, depth loss = 16.800, time = 3.539
Epoch 0/16, Iter 2850/6761, lr 0.001000, train loss = 73.442, depth loss = 20.641, time = 3.583
Epoch 0/16, Iter 2900/6761, lr 0.001000, train loss = 16.579, depth loss = 4.612, time = 3.896
Epoch 0/16, Iter 2950/6761, lr 0.001000, train loss = 29.706, depth loss = 8.201, time = 3.287
Epoch 0/16, Iter 3000/6761, lr 0.001000, train loss = 43.651, depth loss = 12.181, time = 3.618
Epoch 0/16, Iter 3050/6761, lr 0.001000, train loss = 42.378, depth loss = 11.881, time = 3.546
Epoch 0/16, Iter 3100/6761, lr 0.001000, train loss = 49.513, depth loss = 13.690, time = 3.585
Epoch 0/16, Iter 3150/6761, lr 0.001000, train loss = 13.891, depth loss = 3.788, time = 3.316
Epoch 0/16, Iter 3200/6761, lr 0.001000, train loss = 50.743, depth loss = 14.169, time = 3.790
Epoch 0/16, Iter 3250/6761, lr 0.001000, train loss = 40.496, depth loss = 11.367, time = 3.654
Epoch 0/16, Iter 3300/6761, lr 0.001000, train loss = 20.573, depth loss = 5.252, time = 3.344
Epoch 0/16, Iter 3350/6761, lr 0.001000, train loss = 37.814, depth loss = 10.076, time = 3.669
Epoch 0/16, Iter 3400/6761, lr 0.001000, train loss = 35.269, depth loss = 9.279, time = 3.445
Epoch 0/16, Iter 3450/6761, lr 0.001000, train loss = 52.904, depth loss = 14.652, time = 3.715
Epoch 0/16, Iter 3500/6761, lr 0.001000, train loss = 17.504, depth loss = 4.250, time = 3.681
Epoch 0/16, Iter 3550/6761, lr 0.001000, train loss = 7.026, depth loss = 1.844, time = 3.710
Epoch 0/16, Iter 3600/6761, lr 0.001000, train loss = 14.604, depth loss = 3.985, time = 3.655
Epoch 0/16, Iter 3650/6761, lr 0.001000, train loss = 9.647, depth loss = 2.559, time = 3.524
Epoch 0/16, Iter 3700/6761, lr 0.001000, train loss = 8.847, depth loss = 2.316, time = 3.735
Epoch 0/16, Iter 3750/6761, lr 0.001000, train loss = 11.098, depth loss = 2.963, time = 3.422
Epoch 0/16, Iter 3800/6761, lr 0.001000, train loss = 13.399, depth loss = 3.676, time = 3.355
Epoch 0/16, Iter 3850/6761, lr 0.001000, train loss = 27.647, depth loss = 7.629, time = 3.803
Epoch 0/16, Iter 3900/6761, lr 0.001000, train loss = 42.368, depth loss = 11.781, time = 3.633
Epoch 0/16, Iter 3950/6761, lr 0.001000, train loss = 3.764, depth loss = 0.928, time = 3.459
Epoch 0/16, Iter 4000/6761, lr 0.001000, train loss = 8.215, depth loss = 2.174, time = 3.821
Epoch 0/16, Iter 4050/6761, lr 0.001000, train loss = 12.506, depth loss = 3.414, time = 3.256
Epoch 0/16, Iter 4100/6761, lr 0.001000, train loss = 15.793, depth loss = 4.216, time = 3.691
Epoch 0/16, Iter 4150/6761, lr 0.001000, train loss = 10.112, depth loss = 2.657, time = 4.180
Epoch 0/16, Iter 4200/6761, lr 0.001000, train loss = 26.501, depth loss = 7.031, time = 3.591
Epoch 0/16, Iter 4250/6761, lr 0.001000, train loss = 40.098, depth loss = 10.830, time = 3.308
Epoch 0/16, Iter 4300/6761, lr 0.001000, train loss = 48.754, depth loss = 13.379, time = 3.647
Epoch 0/16, Iter 4350/6761, lr 0.001000, train loss = 81.993, depth loss = 22.463, time = 4.114
Epoch 0/16, Iter 4400/6761, lr 0.001000, train loss = 41.643, depth loss = 11.423, time = 4.299
Epoch 0/16, Iter 4450/6761, lr 0.001000, train loss = 36.906, depth loss = 9.853, time = 3.321
Epoch 0/16, Iter 4500/6761, lr 0.001000, train loss = 7.185, depth loss = 1.766, time = 4.148
Epoch 0/16, Iter 4550/6761, lr 0.001000, train loss = 16.017, depth loss = 4.165, time = 3.546
Epoch 0/16, Iter 4600/6761, lr 0.001000, train loss = 28.329, depth loss = 7.712, time = 4.014
Epoch 0/16, Iter 4650/6761, lr 0.001000, train loss = 13.712, depth loss = 3.651, time = 3.321
Epoch 0/16, Iter 4700/6761, lr 0.001000, train loss = 8.428, depth loss = 2.165, time = 3.572
Epoch 0/16, Iter 4750/6761, lr 0.001000, train loss = 10.268, depth loss = 2.711, time = 3.834
Epoch 0/16, Iter 4800/6761, lr 0.001000, train loss = 11.069, depth loss = 2.982, time = 3.698
Epoch 0/16, Iter 4850/6761, lr 0.001000, train loss = 23.761, depth loss = 6.545, time = 3.289
Epoch 0/16, Iter 4900/6761, lr 0.001000, train loss = 56.829, depth loss = 16.086, time = 3.373
Epoch 0/16, Iter 4950/6761, lr 0.001000, train loss = 38.022, depth loss = 10.626, time = 3.664
Epoch 0/16, Iter 5000/6761, lr 0.001000, train loss = 27.770, depth loss = 7.723, time = 3.339
Epoch 0/16, Iter 5050/6761, lr 0.001000, train loss = 23.411, depth loss = 6.468, time = 3.495
Epoch 0/16, Iter 5100/6761, lr 0.001000, train loss = 39.064, depth loss = 10.838, time = 3.809
Epoch 0/16, Iter 5150/6761, lr 0.001000, train loss = 51.710, depth loss = 14.562, time = 4.117
Epoch 0/16, Iter 5200/6761, lr 0.001000, train loss = 35.869, depth loss = 10.045, time = 3.244
Epoch 0/16, Iter 5250/6761, lr 0.001000, train loss = 18.318, depth loss = 5.157, time = 3.757
Epoch 0/16, Iter 5300/6761, lr 0.001000, train loss = 21.247, depth loss = 5.849, time = 3.608
Epoch 0/16, Iter 5350/6761, lr 0.001000, train loss = 11.808, depth loss = 3.172, time = 3.957
Epoch 0/16, Iter 5400/6761, lr 0.001000, train loss = 29.785, depth loss = 8.208, time = 3.557
Epoch 0/16, Iter 5450/6761, lr 0.001000, train loss = 17.782, depth loss = 4.862, time = 3.449
Epoch 0/16, Iter 5500/6761, lr 0.001000, train loss = 15.658, depth loss = 4.193, time = 3.641
Epoch 0/16, Iter 5550/6761, lr 0.001000, train loss = 25.802, depth loss = 7.186, time = 3.394
Epoch 0/16, Iter 5600/6761, lr 0.001000, train loss = 35.308, depth loss = 9.813, time = 3.077
Epoch 0/16, Iter 5650/6761, lr 0.001000, train loss = 11.072, depth loss = 3.004, time = 3.348
Epoch 0/16, Iter 5700/6761, lr 0.001000, train loss = 32.124, depth loss = 8.774, time = 3.541
Epoch 0/16, Iter 5750/6761, lr 0.001000, train loss = 36.937, depth loss = 9.848, time = 3.599
Epoch 0/16, Iter 5800/6761, lr 0.001000, train loss = 55.800, depth loss = 15.347, time = 3.660
Epoch 0/16, Iter 5850/6761, lr 0.001000, train loss = 74.443, depth loss = 20.758, time = 3.536
Epoch 0/16, Iter 5900/6761, lr 0.001000, train loss = 19.443, depth loss = 5.107, time = 3.558
Epoch 0/16, Iter 5950/6761, lr 0.001000, train loss = 10.503, depth loss = 2.835, time = 3.371
Epoch 0/16, Iter 6000/6761, lr 0.001000, train loss = 16.364, depth loss = 4.376, time = 4.261
Epoch 0/16, Iter 6050/6761, lr 0.001000, train loss = 14.935, depth loss = 4.086, time = 4.048
Epoch 0/16, Iter 6100/6761, lr 0.001000, train loss = 58.026, depth loss = 15.758, time = 3.676
Epoch 0/16, Iter 6150/6761, lr 0.001000, train loss = 47.356, depth loss = 12.849, time = 3.794
Epoch 0/16, Iter 6200/6761, lr 0.001000, train loss = 10.341, depth loss = 2.719, time = 4.187
Epoch 0/16, Iter 6250/6761, lr 0.001000, train loss = 32.729, depth loss = 9.116, time = 3.713
Epoch 0/16, Iter 6300/6761, lr 0.001000, train loss = 31.270, depth loss = 8.367, time = 3.465
Epoch 0/16, Iter 6350/6761, lr 0.001000, train loss = 20.640, depth loss = 5.463, time = 3.438
Epoch 0/16, Iter 6400/6761, lr 0.001000, train loss = 6.597, depth loss = 1.686, time = 3.948
Epoch 0/16, Iter 6450/6761, lr 0.001000, train loss = 12.823, depth loss = 3.519, time = 3.817
Epoch 0/16, Iter 6500/6761, lr 0.001000, train loss = 9.307, depth loss = 2.416, time = 3.469
Epoch 0/16, Iter 6550/6761, lr 0.001000, train loss = 6.002, depth loss = 1.521, time = 3.268
Epoch 0/16, Iter 6600/6761, lr 0.001000, train loss = 7.488, depth loss = 1.856, time = 3.611
Epoch 0/16, Iter 6650/6761, lr 0.001000, train loss = 14.924, depth loss = 4.034, time = 4.192
Epoch 0/16, Iter 6700/6761, lr 0.001000, train loss = 21.339, depth loss = 5.801, time = 3.270
Epoch 0/16, Iter 6750/6761, lr 0.001000, train loss = 42.263, depth loss = 11.584, time = 3.472
Epoch 0/16, Iter 0/6174, test loss = 29.944, depth loss = 8.285, time = 2.302496
Epoch 0/16, Iter 50/6174, test loss = 11.301, depth loss = 3.049, time = 0.702342
Epoch 0/16, Iter 100/6174, test loss = 6.855, depth loss = 1.799, time = 0.632840
Epoch 0/16, Iter 150/6174, test loss = 15.686, depth loss = 4.312, time = 0.602401
Epoch 0/16, Iter 200/6174, test loss = 45.223, depth loss = 12.650, time = 0.634819
Epoch 0/16, Iter 250/6174, test loss = 34.750, depth loss = 9.625, time = 0.706362
Epoch 0/16, Iter 300/6174, test loss = 8.120, depth loss = 2.116, time = 0.659585
Epoch 0/16, Iter 350/6174, test loss = 9.376, depth loss = 2.448, time = 0.672245
Epoch 0/16, Iter 400/6174, test loss = 7.086, depth loss = 1.815, time = 0.660250
Epoch 0/16, Iter 450/6174, test loss = 6.338, depth loss = 1.634, time = 0.659150
Epoch 0/16, Iter 500/6174, test loss = 8.341, depth loss = 2.208, time = 0.618177
Epoch 0/16, Iter 550/6174, test loss = 5.293, depth loss = 1.357, time = 0.755135
Epoch 0/16, Iter 600/6174, test loss = 4.734, depth loss = 1.225, time = 0.718261
Epoch 0/16, Iter 650/6174, test loss = 5.605, depth loss = 1.472, time = 0.759085
Epoch 0/16, Iter 700/6174, test loss = 6.999, depth loss = 1.810, time = 0.695872
Epoch 0/16, Iter 750/6174, test loss = 5.361, depth loss = 1.351, time = 0.736608
Epoch 0/16, Iter 800/6174, test loss = 4.905, depth loss = 1.239, time = 0.710506
Epoch 0/16, Iter 850/6174, test loss = 4.942, depth loss = 1.183, time = 0.692469
Epoch 0/16, Iter 900/6174, test loss = 9.515, depth loss = 2.485, time = 0.623697
Epoch 0/16, Iter 950/6174, test loss = 21.408, depth loss = 5.879, time = 0.638350
Epoch 0/16, Iter 1000/6174, test loss = 18.493, depth loss = 5.136, time = 0.761423
Epoch 0/16, Iter 1050/6174, test loss = 21.454, depth loss = 5.942, time = 0.729115
Epoch 0/16, Iter 1100/6174, test loss = 14.762, depth loss = 4.059, time = 0.676773
Epoch 0/16, Iter 1150/6174, test loss = 30.713, depth loss = 8.547, time = 0.653848
Epoch 0/16, Iter 1200/6174, test loss = 48.684, depth loss = 13.757, time = 0.700937
Epoch 0/16, Iter 1250/6174, test loss = 40.195, depth loss = 11.366, time = 0.530134
Epoch 0/16, Iter 1300/6174, test loss = 22.489, depth loss = 6.262, time = 0.713674
Epoch 0/16, Iter 1350/6174, test loss = 11.993, depth loss = 3.311, time = 0.719619
Epoch 0/16, Iter 1400/6174, test loss = 134.035, depth loss = 37.692, time = 0.719515
Epoch 0/16, Iter 1450/6174, test loss = 124.958, depth loss = 35.188, time = 0.664413
Epoch 0/16, Iter 1500/6174, test loss = 88.943, depth loss = 25.143, time = 0.667491
Epoch 0/16, Iter 1550/6174, test loss = 93.360, depth loss = 26.581, time = 0.685507
Epoch 0/16, Iter 1600/6174, test loss = 140.746, depth loss = 40.481, time = 0.671944
Epoch 0/16, Iter 1650/6174, test loss = 171.829, depth loss = 49.165, time = 0.672424
Epoch 0/16, Iter 1700/6174, test loss = 144.675, depth loss = 41.456, time = 0.654990
Epoch 0/16, Iter 1750/6174, test loss = 2.917, depth loss = 0.777, time = 0.756384
Epoch 0/16, Iter 1800/6174, test loss = 2.860, depth loss = 0.715, time = 0.781231
Epoch 0/16, Iter 1850/6174, test loss = 5.766, depth loss = 1.484, time = 0.725376
Epoch 0/16, Iter 1900/6174, test loss = 36.147, depth loss = 9.972, time = 0.763163
Epoch 0/16, Iter 1950/6174, test loss = 9.414, depth loss = 2.272, time = 0.726036
Epoch 0/16, Iter 2000/6174, test loss = 7.505, depth loss = 1.818, time = 0.719459
Epoch 0/16, Iter 2050/6174, test loss = 3.028, depth loss = 0.576, time = 0.753752
Epoch 0/16, Iter 2100/6174, test loss = 192.720, depth loss = 52.481, time = 0.717295
Epoch 0/16, Iter 2150/6174, test loss = 177.029, depth loss = 48.510, time = 0.721536
Epoch 0/16, Iter 2200/6174, test loss = 180.894, depth loss = 50.011, time = 0.631773
Epoch 0/16, Iter 2250/6174, test loss = 200.352, depth loss = 56.085, time = 0.765803
Epoch 0/16, Iter 2300/6174, test loss = 179.056, depth loss = 50.146, time = 0.771192
Epoch 0/16, Iter 2350/6174, test loss = 166.613, depth loss = 46.407, time = 0.637030
Epoch 0/16, Iter 2400/6174, test loss = 157.084, depth loss = 43.413, time = 0.709478
Epoch 0/16, Iter 2450/6174, test loss = 19.826, depth loss = 5.575, time = 0.541720
Epoch 0/16, Iter 2500/6174, test loss = 8.934, depth loss = 2.348, time = 0.637965
Epoch 0/16, Iter 2550/6174, test loss = 12.425, depth loss = 3.354, time = 0.600191
Epoch 0/16, Iter 2600/6174, test loss = 31.704, depth loss = 8.800, time = 0.647687
Epoch 0/16, Iter 2650/6174, test loss = 34.116, depth loss = 9.520, time = 0.571552
Epoch 0/16, Iter 2700/6174, test loss = 9.935, depth loss = 2.626, time = 0.581568
Epoch 0/16, Iter 2750/6174, test loss = 22.486, depth loss = 6.185, time = 0.734419
Epoch 0/16, Iter 2800/6174, test loss = 13.802, depth loss = 3.695, time = 0.691330
Epoch 0/16, Iter 2850/6174, test loss = 6.549, depth loss = 1.700, time = 0.727922
Epoch 0/16, Iter 2900/6174, test loss = 10.219, depth loss = 2.732, time = 0.641761
Epoch 0/16, Iter 2950/6174, test loss = 11.552, depth loss = 3.114, time = 0.661168
Epoch 0/16, Iter 3000/6174, test loss = 14.440, depth loss = 3.903, time = 0.657897
Epoch 0/16, Iter 3050/6174, test loss = 6.093, depth loss = 1.531, time = 0.705706
Epoch 0/16, Iter 3100/6174, test loss = 31.271, depth loss = 8.863, time = 0.630620
Epoch 0/16, Iter 3150/6174, test loss = 42.309, depth loss = 11.957, time = 0.630693
Epoch 0/16, Iter 3200/6174, test loss = 101.605, depth loss = 28.886, time = 0.631842
Epoch 0/16, Iter 3250/6174, test loss = 87.297, depth loss = 24.573, time = 0.629117
Epoch 0/16, Iter 3300/6174, test loss = 84.577, depth loss = 23.714, time = 0.686859
Epoch 0/16, Iter 3350/6174, test loss = 26.301, depth loss = 6.728, time = 0.667274
Epoch 0/16, Iter 3400/6174, test loss = 33.523, depth loss = 8.913, time = 0.606604
Epoch 0/16, Iter 3450/6174, test loss = 81.694, depth loss = 22.363, time = 0.729864
Epoch 0/16, Iter 3500/6174, test loss = 40.621, depth loss = 10.928, time = 0.705366
Epoch 0/16, Iter 3550/6174, test loss = 14.241, depth loss = 3.708, time = 0.683589
Epoch 0/16, Iter 3600/6174, test loss = 7.641, depth loss = 2.032, time = 0.663324
Epoch 0/16, Iter 3650/6174, test loss = 5.947, depth loss = 1.529, time = 0.699152
Epoch 0/16, Iter 3700/6174, test loss = 7.426, depth loss = 2.023, time = 0.645872
Epoch 0/16, Iter 3750/6174, test loss = 8.702, depth loss = 2.367, time = 0.708371
Epoch 0/16, Iter 3800/6174, test loss = 5.938, depth loss = 1.629, time = 0.661257
Epoch 0/16, Iter 3850/6174, test loss = 6.923, depth loss = 1.818, time = 0.601507
Epoch 0/16, Iter 3900/6174, test loss = 5.338, depth loss = 1.411, time = 0.576996
Epoch 0/16, Iter 3950/6174, test loss = 3.775, depth loss = 0.945, time = 0.583073
Epoch 0/16, Iter 4000/6174, test loss = 4.460, depth loss = 1.139, time = 0.552012
Epoch 0/16, Iter 4050/6174, test loss = 4.137, depth loss = 1.059, time = 0.677775
Epoch 0/16, Iter 4100/6174, test loss = 4.740, depth loss = 1.203, time = 0.679986
Epoch 0/16, Iter 4150/6174, test loss = 14.702, depth loss = 3.751, time = 0.756100
Epoch 0/16, Iter 4200/6174, test loss = 18.013, depth loss = 4.510, time = 0.748286
Epoch 0/16, Iter 4250/6174, test loss = 18.052, depth loss = 4.082, time = 0.699700
Epoch 0/16, Iter 4300/6174, test loss = 20.000, depth loss = 4.040, time = 0.637738
Epoch 0/16, Iter 4350/6174, test loss = 27.221, depth loss = 6.046, time = 0.733264
Epoch 0/16, Iter 4400/6174, test loss = 19.287, depth loss = 4.222, time = 0.713475
Epoch 0/16, Iter 4450/6174, test loss = 11.767, depth loss = 2.407, time = 0.619798
Epoch 0/16, Iter 4500/6174, test loss = 7.038, depth loss = 1.823, time = 0.605823
Epoch 0/16, Iter 4550/6174, test loss = 5.574, depth loss = 1.368, time = 0.609102
Epoch 0/16, Iter 4600/6174, test loss = 4.800, depth loss = 1.172, time = 0.600697
Epoch 0/16, Iter 4650/6174, test loss = 4.416, depth loss = 1.083, time = 0.704856
Epoch 0/16, Iter 4700/6174, test loss = 4.295, depth loss = 1.050, time = 0.679845
Epoch 0/16, Iter 4750/6174, test loss = 6.184, depth loss = 1.548, time = 0.692534
Epoch 0/16, Iter 4800/6174, test loss = 6.479, depth loss = 1.623, time = 0.644291
Epoch 0/16, Iter 4850/6174, test loss = 15.004, depth loss = 4.155, time = 0.808299
Epoch 0/16, Iter 4900/6174, test loss = 35.211, depth loss = 10.223, time = 0.710172
Epoch 0/16, Iter 4950/6174, test loss = 19.544, depth loss = 5.505, time = 0.686960
Epoch 0/16, Iter 5000/6174, test loss = 36.019, depth loss = 10.032, time = 0.695785
Epoch 0/16, Iter 5050/6174, test loss = 12.536, depth loss = 3.335, time = 0.718504
Epoch 0/16, Iter 5100/6174, test loss = 9.033, depth loss = 2.337, time = 0.761055
Epoch 0/16, Iter 5150/6174, test loss = 43.367, depth loss = 12.205, time = 0.737442
Epoch 0/16, Iter 5200/6174, test loss = 25.747, depth loss = 7.127, time = 0.749719
Epoch 0/16, Iter 5250/6174, test loss = 24.194, depth loss = 6.581, time = 0.704530
Epoch 0/16, Iter 5300/6174, test loss = 33.420, depth loss = 9.310, time = 0.662390
Epoch 0/16, Iter 5350/6174, test loss = 43.738, depth loss = 12.253, time = 0.642999
Epoch 0/16, Iter 5400/6174, test loss = 47.681, depth loss = 13.342, time = 0.655866
Epoch 0/16, Iter 5450/6174, test loss = 42.142, depth loss = 11.990, time = 0.706588
Epoch 0/16, Iter 5500/6174, test loss = 168.568, depth loss = 48.113, time = 0.672908
Epoch 0/16, Iter 5550/6174, test loss = 192.925, depth loss = 55.115, time = 0.658437
Epoch 0/16, Iter 5600/6174, test loss = 196.619, depth loss = 56.081, time = 0.629582
Epoch 0/16, Iter 5650/6174, test loss = 179.359, depth loss = 50.268, time = 0.661800
Epoch 0/16, Iter 5700/6174, test loss = 115.804, depth loss = 31.731, time = 0.668807
Epoch 0/16, Iter 5750/6174, test loss = 121.065, depth loss = 32.613, time = 0.722433
Epoch 0/16, Iter 5800/6174, test loss = 112.903, depth loss = 30.287, time = 0.758998
Epoch 0/16, Iter 5850/6174, test loss = 48.523, depth loss = 13.670, time = 0.839156
Epoch 0/16, Iter 5900/6174, test loss = 36.051, depth loss = 10.152, time = 0.831634
Epoch 0/16, Iter 5950/6174, test loss = 24.420, depth loss = 6.735, time = 0.834886
Epoch 0/16, Iter 6000/6174, test loss = 20.865, depth loss = 5.794, time = 0.850055
Epoch 0/16, Iter 6050/6174, test loss = 20.550, depth loss = 5.693, time = 0.799989
Epoch 0/16, Iter 6100/6174, test loss = 28.263, depth loss = 7.943, time = 0.775253
Epoch 0/16, Iter 6150/6174, test loss = 37.453, depth loss = 10.508, time = 0.834568
avg_test_scalars: {'loss': 38.81966259051265, 'depth_loss': 10.743907427844258, 'abs_depth_error': 11.116454502709445, 'thres2mm_error': 0.2638578387897475, 'thres4mm_error': 0.1874865087552149, 'thres8mm_error': 0.1385380344515418, 'thres14mm_error': 0.10706855903802855, 'thres20mm_error': 0.09057033632353936, 'thres2mm_abserror': 0.6181147925031969, 'thres4mm_abserror': 2.7834019554754197, 'thres8mm_abserror': 5.644558760121218, 'thres14mm_abserror': 10.592579248000165, 'thres20mm_abserror': 16.7070445010374, 'thres>20mm_abserror': 78.14855262736576}
Epoch 1:
Epoch 1/16, Iter 39/6761, lr 0.001000, train loss = 32.053, depth loss = 8.222, time = 3.543
